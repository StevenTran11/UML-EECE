{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "469d7c7c-1944-4df2-9532-4bbed8cf665f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba0d14d50e674462a149f35714be8c34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: xpu:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa738a56100947f784a14ea5bee984f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemma2ForCausalLM(\n",
      "  (model): Gemma2Model(\n",
      "    (embed_tokens): Embedding(256000, 2304, padding_idx=0)\n",
      "    (layers): ModuleList(\n",
      "      (0-25): 26 x Gemma2DecoderLayer(\n",
      "        (self_attn): Gemma2Attention(\n",
      "          (q_proj): Linear(in_features=2304, out_features=2048, bias=False)\n",
      "          (k_proj): Linear(in_features=2304, out_features=1024, bias=False)\n",
      "          (v_proj): Linear(in_features=2304, out_features=1024, bias=False)\n",
      "          (o_proj): Linear(in_features=2048, out_features=2304, bias=False)\n",
      "          (rotary_emb): Gemma2RotaryEmbedding()\n",
      "        )\n",
      "        (mlp): Gemma2MLP(\n",
      "          (gate_proj): Linear(in_features=2304, out_features=9216, bias=False)\n",
      "          (up_proj): Linear(in_features=2304, out_features=9216, bias=False)\n",
      "          (down_proj): Linear(in_features=9216, out_features=2304, bias=False)\n",
      "          (act_fn): PytorchGELUTanh()\n",
      "        )\n",
      "        (input_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
      "        (pre_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
      "        (post_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
      "        (post_attention_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=2304, out_features=256000, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# import necessary packages\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()\n",
    "\n",
    "#model_id = \"google/gemma-1.1-2b-it\"\n",
    "model_id = \"google/gemma-2-2b-it\"\n",
    "#model_id = \"google/gemma-2-9b-it\"\n",
    "#model_id = \"google/gemma-2-27b-it\"\n",
    "#model_id = \"meta-llama/Llama-2-7b-hf\"\n",
    "#device = \"cuda\"\n",
    "USE_CPU = False\n",
    "device = \"xpu:0\" if torch.xpu.is_available() else \"cpu\"\n",
    "if USE_CPU:\n",
    "    device = \"cpu\"\n",
    "print(f\"using device: {device}\")\n",
    "\n",
    "# Let's load the tokenizer first\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# We could typically quantize the model to reduce its weight\n",
    "# But to simplify the process, we won't quantize it in this notebook\n",
    "\n",
    "# Let's load the chosen model\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id).to(device)\n",
    "\n",
    "print(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b08d2ea2-00eb-4c8f-9d2f-8c914a0ff3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List the winners of the World Series from 2010 to 2025 in JSON format.  The winner of 2024 was the dodgers.  Explain why 2025 cannot be included in the list.\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"WorldSeriesWinners\": [\n",
      "    {\n",
      "      \"Year\": 2010,\n",
      "      \"Winner\": \"St. Louis Cardinals\"\n",
      "    },\n",
      "    {\n",
      "      \"Year\": 2011,\n",
      "      \"Winner\": \"Texas Rangers\"\n",
      "    },\n",
      "    {\n",
      "      \"Year\": 2012,\n",
      "      \"Winner\": \"San Francisco Giants\"\n",
      "    },\n",
      "    {\n",
      "      \"Year\": 2013,\n",
      "      \"Winner\": \"Boston Red Sox\"\n",
      "    },\n",
      "    {\n",
      "      \"Year\": 2014,\n",
      "      \"Winner\": \"Kansas City Royals\"\n",
      "    },\n",
      "    {\n",
      "      \"Year\": 2015,\n",
      "      \"Winner\": \"Kansas City Royals\"\n",
      "    },\n",
      "    {\n",
      "      \"Year\": 2016,\n",
      "      \"Winner\": \"Chicago Cubs\"\n",
      "    },\n",
      "    {\n",
      "      \"Year\": 2017,\n",
      "      \"Winner\": \"Houston Astros\"\n",
      "    },\n",
      "    {\n",
      "      \"Year\": 2018,\n",
      "      \"Winner\": \"Boston Red Sox\"\n",
      "    },\n",
      "    {\n",
      "      \"Year\": 2019,\n",
      "      \"Winner\": \"Washington Nationals\"\n",
      "    },\n",
      "    {\n",
      "      \"Year\": 2020,\n",
      "      \"Winner\": \"Los Angeles Dodgers\"\n",
      "    },\n",
      "    {\n",
      "      \"Year\": 2021,\n",
      "      \"Winner\": \"Atlanta Braves\"\n",
      "    },\n",
      "    {\n",
      "      \"Year\": 2022,\n",
      "      \"Winner\": \"Houston Astros\"\n",
      "    },\n",
      "    {\n",
      "      \"Year\": 2023,\n",
      "      \"Winner\": \"Philadelphia Phillies\"\n",
      "    },\n",
      "    {\n",
      "      \"Year\": 2024,\n",
      "      \"Winner\": \"Los Angeles Dodgers\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "**Answer:**\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"WorldSeriesWinners\": [\n",
      "    {\n",
      "      \"Year\": 2010,\n",
      "      \"Winner\": \"St. Louis Cardinals\"\n",
      "    },\n",
      "    {\n",
      "      \"Year\": 2011,\n",
      "      \"Winner\": \"Texas Rangers\"\n",
      "    },\n",
      "    {\n",
      "      \"Year\": 2012,\n",
      "      \"Winner\": \"San Francisco Giants\"\n",
      "    },\n",
      "    {\n",
      "      \"Year\": 2013,\n",
      "      \"Winner\": \"Boston Red Sox\"\n",
      "    },\n",
      "    {\n",
      "      \"Year\": 2014,\n",
      "      \"Winner\": \"Kansas City Royals\"\n",
      "    },\n",
      "    {\n",
      "      \"Year\": 2015,\n",
      "      \"Winner\": \"Kansas City Royals\"\n",
      "    },\n",
      "    {\n",
      "      \"Year\": 2016,\n",
      "      \"Winner\": \"Chicago Cubs\"\n",
      "    },\n",
      "    {\n",
      "      \"Year\": 2017,\n",
      "      \"Winner\": \"Houston Astros\"\n",
      "    },\n",
      "    {\n",
      "      \"Year\": 2018,\n",
      "      \"Winner\": \"Boston Red Sox\"\n",
      "    },\n",
      "    {\n",
      "      \"Year\": 2019,\n",
      "      \"Winner\": \"Washington Nationals\"\n",
      "    },\n",
      "    {\n",
      "      \"Year\": 2020,\n",
      "      \"Winner\": \"Los Angeles Dodgers\"\n",
      "    },\n",
      "    {\n",
      "      \"Year\": 2021,\n",
      "      \"Winner\": \"Atlanta Braves\"\n",
      "    },\n",
      "    {\n",
      "      \"Year\": 2022,\n",
      "      \"Winner\": \"Houston Astros\"\n",
      "    },\n",
      "    {\n",
      "      \"Year\": 2023,\n",
      "      \"Winner\": \"Philadelphia Phillies\"\n",
      "    },\n",
      "    {\n",
      "      \"Year\": 2024,\n",
      "      \"Winner\": \"Los Angeles Dodgers\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "**Explanation:**\n",
      "\n",
      "* **2025 cannot be included in the list.**  The World Series for 2025 has not yet been played. \n",
      "\n",
      "Let me know if you have any other questions! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"List the winners of the World Series from 2010 to 2025 in JSON format.  The winner of 2024 was the dodgers.  Explain why 2025 cannot be included\"\n",
    "inputs = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(inputs, max_new_tokens=1024)\n",
    "text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fba390-21df-420e-a274-2fcb733510c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.6",
   "language": "python",
   "name": "pytorch-2.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
