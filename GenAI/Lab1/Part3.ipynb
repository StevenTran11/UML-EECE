{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5f640f1-51fe-446f-b354-5aae6fd5b581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: peft==0.10.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (0.10.0)\n",
      "Requirement already satisfied: datasets in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (3.3.2)\n",
      "Requirement already satisfied: ipywidgets in /opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (8.1.5)\n",
      "Requirement already satisfied: transformers==4.38.2 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (4.38.2)\n",
      "Requirement already satisfied: wandb in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (0.19.7)\n",
      "Requirement already satisfied: trl==0.8.3 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (0.8.3)\n",
      "Requirement already satisfied: accelerate==0.27.2 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (0.27.2)\n",
      "Requirement already satisfied: bitsandbytes==0.43.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (0.43.0)\n",
      "Requirement already satisfied: scipy==1.12.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from peft==0.10.0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from peft==0.10.0) (22.0)\n",
      "Requirement already satisfied: psutil in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from peft==0.10.0) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from peft==0.10.0) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from peft==0.10.0) (2.5.1+cxx11.abi)\n",
      "Requirement already satisfied: tqdm in /opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from peft==0.10.0) (4.67.1)\n",
      "Requirement already satisfied: safetensors in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from peft==0.10.0) (0.5.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from peft==0.10.0) (0.29.1)\n",
      "Requirement already satisfied: filelock in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from transformers==4.38.2) (3.17.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from transformers==4.38.2) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from transformers==4.38.2) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from transformers==4.38.2) (0.15.2)\n",
      "Requirement already satisfied: tyro>=0.5.11 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from trl==0.8.3) (0.9.16)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from datasets) (3.11.12)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from ipywidgets) (8.32.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.12 in /opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from wandb) (8.1.8)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from wandb) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from wandb) (4.3.6)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from wandb) (5.29.3)\n",
      "Requirement already satisfied: pydantic<3,>=2.6 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from wandb) (2.10.6)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from wandb) (2.22.0)\n",
      "Requirement already satisfied: setproctitle in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from wandb) (1.3.4)\n",
      "Requirement already satisfied: setuptools in /opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from wandb) (75.8.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from wandb) (4.12.2)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from aiohttp->datasets) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from aiohttp->datasets) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: decorator in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: exceptiongroup in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (1.2.2)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from pydantic<3,>=2.6->wandb) (2.27.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from requests->transformers==4.38.2) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from requests->transformers==4.38.2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from requests->transformers==4.38.2) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from requests->transformers==4.38.2) (2024.12.14)\n",
      "Requirement already satisfied: networkx in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.0) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.10.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.13.0->peft==0.10.0) (1.3.0)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.8.3) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.8.3) (13.9.4)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.8.3) (1.7.1)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.8.3) (4.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.8.3) (3.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.10.0) (2.1.5)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.8.3) (0.1.2)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import site\n",
    "import os\n",
    "\n",
    "# Install the required packages\n",
    "!{sys.executable} -m pip install peft==0.10.0 datasets ipywidgets transformers==4.38.2 wandb trl==0.8.3 accelerate==0.27.2 bitsandbytes==0.43.0 scipy==1.12.0\n",
    "\n",
    "\n",
    "# Get the site-packages directory\n",
    "site_packages_dir = site.getsitepackages()[0]\n",
    "\n",
    "# add the site pkg directory where these pkgs are insalled to the top of sys.path\n",
    "if not os.access(site_packages_dir, os.W_OK):\n",
    "    user_site_packages_dir = site.getusersitepackages()\n",
    "    if user_site_packages_dir in sys.path:\n",
    "        sys.path.remove(user_site_packages_dir)\n",
    "    sys.path.insert(0, user_site_packages_dir)\n",
    "else:\n",
    "    if site_packages_dir in sys.path:\n",
    "        sys.path.remove(site_packages_dir)\n",
    "    sys.path.insert(0, site_packages_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "072b1712-01e0-41aa-a8df-3fbc0f2a59dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of physical cores: 96\n",
      "Number of cores per socket: 48\n",
      "OpenMP environment variables:\n",
      "  - OMP_NUM_THREADS: 96\n",
      "  - OMP_PROC_BIND: close\n",
      "  - OMP_PLACES: cores\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import psutil\n",
    "\n",
    "num_physical_cores = psutil.cpu_count(logical=False)\n",
    "num_cores_per_socket = num_physical_cores // 2\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"0\"\n",
    "#HF_TOKEN = os.environ[\"HF_TOKEN\"]\n",
    "\n",
    "# Set the LD_PRELOAD environment variable\n",
    "ld_preload = os.environ.get(\"LD_PRELOAD\", \"\")\n",
    "conda_prefix = os.environ.get(\"CONDA_PREFIX\", \"\")\n",
    "# Improve memory allocation performance, if tcmalloc is not available, please comment this line out\n",
    "os.environ[\"LD_PRELOAD\"] = f\"{ld_preload}:{conda_prefix}/lib/libtcmalloc.so\"\n",
    "# Reduce the overhead of submitting commands to the GPU\n",
    "os.environ[\"SYCL_PI_LEVEL_ZERO_USE_IMMEDIATE_COMMANDLISTS\"] = \"1\"\n",
    "# reducing memory accesses by fusing SDP ops\n",
    "os.environ[\"ENABLE_SDP_FUSION\"] = \"1\"\n",
    "# set openMP threads to number of physical cores\n",
    "os.environ[\"OMP_NUM_THREADS\"] = str(num_physical_cores)\n",
    "# Set the thread affinity policy\n",
    "os.environ[\"OMP_PROC_BIND\"] = \"close\"\n",
    "# Set the places for thread pinning\n",
    "os.environ[\"OMP_PLACES\"] = \"cores\"\n",
    "\n",
    "print(f\"Number of physical cores: {num_physical_cores}\")\n",
    "print(f\"Number of cores per socket: {num_cores_per_socket}\")\n",
    "print(f\"OpenMP environment variables:\")\n",
    "print(f\"  - OMP_NUM_THREADS: {os.environ['OMP_NUM_THREADS']}\")\n",
    "print(f\"  - OMP_PROC_BIND: {os.environ['OMP_PROC_BIND']}\")\n",
    "print(f\"  - OMP_PLACES: {os.environ['OMP_PLACES']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f6d0335-9764-4bad-837a-34587227d364",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W224 03:29:49.994599155 OperatorEntry.cpp:155] Warning: Warning only once for all operators,  other operators may also be overridden.\n",
      "  Overriding a previously registered kernel for the same operator and the same dispatch key\n",
      "  operator: aten::_cummax_helper(Tensor self, Tensor(a!) values, Tensor(b!) indices, int dim) -> ()\n",
      "    registered at /build/pytorch/build/aten/src/ATen/RegisterSchema.cpp:6\n",
      "  dispatch key: XPU\n",
      "  previous kernel: registered at /build/pytorch/build/aten/src/ATen/RegisterCPU.cpp:30476\n",
      "       new kernel: registered at /build/intel-pytorch-extension/build/Release/csrc/gpu/csrc/aten/generated/ATen/RegisterXPU.cpp:2971 (function operator())\n",
      "ERROR: ld.so: object '/lib/libtcmalloc.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p>XPU (Intel(R) Data Center GPU Max 1100) :: Memory: Reserved=19.717 GB, Allocated=19.309 GB, Max Reserved=37.549 GB, Max Allocated=26.313 GB</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import asyncio\n",
    "import threading\n",
    "import torch\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import torch\n",
    "import intel_extension_for_pytorch as ipex\n",
    "\n",
    "if torch.xpu.is_available():\n",
    "    torch.xpu.empty_cache()\n",
    "    \n",
    "    def get_memory_usage():\n",
    "        memory_reserved = round(torch.xpu.memory_reserved() / 1024**3, 3)\n",
    "        memory_allocated = round(torch.xpu.memory_allocated() / 1024**3, 3)\n",
    "        max_memory_reserved = round(torch.xpu.max_memory_reserved() / 1024**3, 3)\n",
    "        max_memory_allocated = round(torch.xpu.max_memory_allocated() / 1024**3, 3)\n",
    "        return memory_reserved, memory_allocated, max_memory_reserved, max_memory_allocated\n",
    "   \n",
    "    def print_memory_usage():\n",
    "        device_name = torch.xpu.get_device_name()\n",
    "        print(f\"XPU Name: {device_name}\")\n",
    "        memory_reserved, memory_allocated, max_memory_reserved, max_memory_allocated = get_memory_usage()\n",
    "        memory_usage_text = f\"XPU Memory: Reserved={memory_reserved} GB, Allocated={memory_allocated} GB, Max Reserved={max_memory_reserved} GB, Max Allocated={max_memory_allocated} GB\"\n",
    "        print(f\"\\r{memory_usage_text}\", end=\"\", flush=True)\n",
    "    \n",
    "    async def display_memory_usage(output):\n",
    "        device_name = torch.xpu.get_device_name()\n",
    "        output.update(HTML(f\"<p>XPU Name: {device_name}</p>\"))\n",
    "        while True:\n",
    "            memory_reserved, memory_allocated, max_memory_reserved, max_memory_allocated = get_memory_usage()\n",
    "            memory_usage_text = f\"XPU ({device_name}) :: Memory: Reserved={memory_reserved} GB, Allocated={memory_allocated} GB, Max Reserved={max_memory_reserved} GB, Max Allocated={max_memory_allocated} GB\"\n",
    "            output.update(HTML(f\"<p>{memory_usage_text}</p>\"))\n",
    "            await asyncio.sleep(5)\n",
    "    \n",
    "    def start_memory_monitor(output):\n",
    "        loop = asyncio.new_event_loop()\n",
    "        asyncio.set_event_loop(loop)\n",
    "        loop.create_task(display_memory_usage(output))\n",
    "        thread = threading.Thread(target=loop.run_forever)\n",
    "        thread.start()    \n",
    "    output = display(display_id=True)\n",
    "    start_memory_monitor(output)\n",
    "else:\n",
    "    print(\"XPU device not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17ebaf91-4137-459a-8d77-7a18531c9982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so: undefined symbol: cadam32bit_grad_fp32\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    # could use q, v and 0 projections as well and comment out the rest\n",
    "    target_modules=[\"q_proj\", \"o_proj\", \n",
    "                    \"v_proj\", \"k_proj\", \n",
    "                    \"gate_proj\", \"up_proj\",\n",
    "                    \"down_proj\"],\n",
    "    task_type=\"CAUSAL_LM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c449d81-78f5-49a9-a10d-10fe1c8294b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8b50193ca7f4fc180e9daed60a0327f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f30dc47-d9d1-4ffd-85d2-db7e24858455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: xpu:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "885f231bbd774bd5af4cf0a7d2657c5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "USE_CPU = False\n",
    "device = \"xpu:0\" if torch.xpu.is_available() else \"cpu\"\n",
    "if USE_CPU:\n",
    "    device = \"cpu\"\n",
    "print(f\"using device: {device}\")\n",
    "\n",
    "model_id = \"google/gemma-2b\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "# Set padding side to the right to ensure proper attention masking during fine-tuning\n",
    "tokenizer.padding_side = \"right\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id).to(device)\n",
    "# Disable caching mechanism to reduce memory usage during fine-tuning\n",
    "model.config.use_cache = False\n",
    "# Configure the model's pre-training tensor parallelism degree to match the fine-tuning setup\n",
    "model.config.pretraining_tp = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e36958d0-b386-4436-9395-257f6474062b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the model before fine-tuning:\n",
      "__________________________________________________\n",
      "What are the main differences between a vegetarian and a vegan diet?\n",
      "Generated Answer: What are the main differences between a vegetarian and a vegan diet?\n",
      "\n",
      "A 100-W lightbulb is plugged into a standard $120-\\mathrm{V}$ (rms) outlet. Find $(a) I_{\\text {mas }}$ and $(b) I_{\\max }$ if a \"slow-motion\" camera were able to show the amplitude of the current more than once in $1.00 \\mathrm{~ms}$.\n",
      "\n",
      "A 100-turn coil has a radius of 4.50 cm and a resistance\n",
      "\n",
      "__________________________________________________\n",
      "__________________________________________________\n",
      "What are some effective strategies for managing stress and anxiety?\n",
      "Generated Answer: What are some effective strategies for managing stress and anxiety?\n",
      "\n",
      "Answer:\n",
      "\n",
      "Step 1/10\n",
      "1. Exercise: Regular exercise can help reduce stress and anxiety by releasing endorphins, which are natural mood-boosting chemicals in the brain.\n",
      "\n",
      "Step 2/10\n",
      "2. Meditation: Practicing meditation can help you focus on your breath and clear your mind, which can help reduce stress and anxiety.\n",
      "\n",
      "Step 3/10\n",
      "3. Journaling: Writing down your thoughts and feelings can help you process and understand\n",
      "\n",
      "__________________________________________________\n",
      "__________________________________________________\n",
      "Can you explain the concept of blockchain technology in simple terms?\n",
      "Generated Answer: Can you explain the concept of blockchain technology in simple terms?\n",
      "\n",
      "Answer:\n",
      "\n",
      "Blockchain technology is a distributed ledger that records transactions between parties in a secure and transparent manner. It is a decentralized system that allows for the creation of a shared record of transactions that cannot be altered or tampered with.\n",
      "Blockchain technology is used in a variety of industries, including finance, healthcare, and supply chain management. It is also being used to create decentralized applications (dApps) that allow users to interact with each other and with the blockchain network.\n",
      "\n",
      "__________________________________________________\n",
      "__________________________________________________\n",
      "What are the key factors that influence the price of crude oil in global markets?\n",
      "Generated Answer: What are the key factors that influence the price of crude oil in global markets?\n",
      "\n",
      "Answer:\n",
      "\n",
      "Step 1/5\n",
      "1. Supply and demand: The most significant factor that influences the price of crude oil in global markets is the supply and demand of crude oil. When there is a surplus of crude oil, the price will decrease, and when there is a shortage, the price will increase.\n",
      "\n",
      "Step 2/5\n",
      "2. Geopolitical factors: Political instability, conflicts, and wars can significantly impact the supply of crude oil. For example, the conflict between\n",
      "\n",
      "__________________________________________________\n",
      "__________________________________________________\n",
      "When did Virgin Australia start operating?\n",
      "Generated Answer: When did Virgin Australia start operating?\n",
      "\n",
      "Virgin Australia started operating in 2000.\n",
      "\n",
      "What is Virgin Australia’s head office?\n",
      "\n",
      "Virgin Australia’s head office is located in Melbourne, Australia.\n",
      "\n",
      "What is Virgin Australia’s IATA code?\n",
      "\n",
      "Virgin Australia’s IATA code is VA.\n",
      "\n",
      "What is Virgin Australia’s call sign?\n",
      "\n",
      "Virgin Australia’s call sign is VA.\n",
      "\n",
      "What is Virgin Australia’s website?\n",
      "\n",
      "Virgin Australia’s website is www.virginaustralia.\n",
      "\n",
      "__________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def generate_response(model, prompt):\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)    \n",
    "    outputs = model.generate(input_ids, max_new_tokens=100,\n",
    "                             eos_token_id=tokenizer.eos_token_id)    \n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "def test_model(model, test_inputs):\n",
    "    \"\"\"quickly test the model using queries.\"\"\"\n",
    "    for input_text in test_inputs:\n",
    "        print(\"__\"*25)\n",
    "        generated_response = generate_response(model, input_text)\n",
    "        print(f\"{input_text}\")\n",
    "        print(f\"Generated Answer: {generated_response}\\n\")\n",
    "        print(\"__\"*25)\n",
    "\n",
    "test_inputs = [\n",
    "    \"What are the main differences between a vegetarian and a vegan diet?\",\n",
    "    \"What are some effective strategies for managing stress and anxiety?\",\n",
    "    \"Can you explain the concept of blockchain technology in simple terms?\",\n",
    "    \"What are the key factors that influence the price of crude oil in global markets?\",\n",
    "    \"When did Virgin Australia start operating?\"\n",
    "]\n",
    "\n",
    "print(\"Testing the model before fine-tuning:\")\n",
    "test_model(model, test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9db0b0f0-c30f-4765-a745-22aec7dc213f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-24 03:30:33,817 - datasets - INFO - PyTorch version 2.5.1+cxx11.abi available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input is: hi, i am a 25yr old female 75kg,1.75cm, noticed i started getting heart palpitations aprox 5mnths ago and over the last few weeks have been getting worse in the sense that they seem to be occuring more often e.g everyday or so and sometimes more than once a day, i get quite scared as if im gonna loose my breath perhaps bcos i get anxious  when they come on as it is abnormal for me, since disscussing with my family my father told me he has the same thing has had it all his life his doctor said his heart just missing a beat (30-40yrs ago) so obviously could be hereditary, i asked him if he gets them everyday he said no,but your heart just missing a beat is not enough for me i smoke cigarettes and this past week have noticed i feel sick when smoking so have seemed to find myself cutting down due to it with no effort at all i have spells were i smoke weed regularly but have found myself not smoking last few weeks i take the occasional recreational drugs and in last few months have been working up to 15hrs a day a few days of the week but as of 2 weeks ago havnt been working not bcos of it..please help me..\n",
      "Output is: Smoking is the sole risk factor to almost all sort of cardiac ailments,,,,keep all risk factors on one side and smoking on the other ...its more serious...smoke weed cannabis and all can cause arrhythmia palpitations as of now I would like to tell you that initially go for thyroid FLA ECG holder test(it will record any missed beat or false beats during 24 hours)treadmill test (to see your effort tolerance)palpitation can be because of underlying cardiac ailment it can be anything from sinus tachycardia(normal heart beats with fast [pacing) to any sort of dangerous arrhythmias or premature contraction or escape beats do not neglect it get these test done immediately\n",
      "Number of examples in the dataset: 2243\n",
      "Fields in the dataset: ['input', 'output']\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_name = \"lavita/ChatDoctor-HealthCareMagic-100k\"\n",
    "dataset = load_dataset(dataset_name, split=\"train\")\n",
    "\n",
    "filtered_dataset = dataset.shuffle(seed=1).select(range(int(len(dataset) * 0.02)))\n",
    "dataset = filtered_dataset\n",
    "\n",
    "print(f\"Input is: {dataset[0]['input']}\")\n",
    "print(f\"Output is: {dataset[0]['output']}\")\n",
    "\n",
    "# Remove unwanted fields from the filtered dataset\n",
    "dataset = filtered_dataset.remove_columns([\"instruction\"])\n",
    "print(f\"Number of examples in the dataset: {len(dataset)}\")\n",
    "print(f\"Fields in the dataset: {list(dataset.features.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93ded994-a426-40aa-a3c5-8eef2e057813",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prompts(batch):\n",
    "    formatted_prompts = []\n",
    "    for question, answer in zip(batch[\"input\"], batch[\"output\"]):\n",
    "        prompt = f\"Question:\\n{question}\\n\\nAnswer:\\n{answer}\"\n",
    "        formatted_prompts.append(prompt)\n",
    "    return {\"text\": formatted_prompts}\n",
    "\n",
    "dataset = dataset.map(format_prompts, batched=True)\n",
    "split_dataset = dataset.train_test_split(test_size=0.2, seed=99)\n",
    "train_dataset = split_dataset[\"train\"]\n",
    "validation_dataset = split_dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c55e144-d1a4-48bc-a215-7c3333ba2983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetuning for max number of steps: 560\n",
      "XPU Name: Intel(R) Data Center GPU Max 1100\n",
      "XPU Memory: Reserved=9.557 GB, Allocated=9.545 GB, Max Reserved=9.557 GB, Max Allocated=9.545 GB"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-24 03:30:45,208 - _logger.py - IPEX - INFO - Currently split master weight for xpu only support sgd\n",
      "2025-02-24 03:30:45,233 - _logger.py - IPEX - INFO - Currently split master weight for xpu only support sgd\n",
      "2025-02-24 03:30:45,441 - wandb.jupyter - ERROR - Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msteven_tran1\u001b[0m (\u001b[33msteven_tran1-umass-lowell\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "ERROR: ld.so: object '/lib/libtcmalloc.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/u36e87926e39e265cdd3b4f969ee677d/genai-labs/wandb/run-20250224_033045-pplxuci7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/steven_tran1-umass-lowell/gemma_dolly-qa/runs/pplxuci7' target=\"_blank\">wobbly-oath-12</a></strong> to <a href='https://wandb.ai/steven_tran1-umass-lowell/gemma_dolly-qa' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/steven_tran1-umass-lowell/gemma_dolly-qa' target=\"_blank\">https://wandb.ai/steven_tran1-umass-lowell/gemma_dolly-qa</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/steven_tran1-umass-lowell/gemma_dolly-qa/runs/pplxuci7' target=\"_blank\">https://wandb.ai/steven_tran1-umass-lowell/gemma_dolly-qa/runs/pplxuci7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='560' max='560' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [560/560 17:26, Epoch 11/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.575100</td>\n",
       "      <td>3.202994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.115700</td>\n",
       "      <td>2.985899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.978200</td>\n",
       "      <td>2.904093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.918500</td>\n",
       "      <td>2.867334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.889700</td>\n",
       "      <td>2.851064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-24 03:33:51,882 - _logger.py - IPEX - INFO - Currently split master weight for xpu only support sgd\n",
      "2025-02-24 03:33:51,902 - _logger.py - IPEX - INFO - Linear BatchNorm folding failed during the optimize process.\n",
      "2025-02-24 03:36:58,004 - _logger.py - IPEX - INFO - Currently split master weight for xpu only support sgd\n",
      "2025-02-24 03:36:58,023 - _logger.py - IPEX - INFO - Linear BatchNorm folding failed during the optimize process.\n",
      "2025-02-24 03:40:04,145 - _logger.py - IPEX - INFO - Currently split master weight for xpu only support sgd\n",
      "2025-02-24 03:40:04,163 - _logger.py - IPEX - INFO - Linear BatchNorm folding failed during the optimize process.\n",
      "2025-02-24 03:43:10,142 - _logger.py - IPEX - INFO - Currently split master weight for xpu only support sgd\n",
      "2025-02-24 03:43:10,161 - _logger.py - IPEX - INFO - Linear BatchNorm folding failed during the optimize process.\n",
      "2025-02-24 03:46:16,157 - _logger.py - IPEX - INFO - Currently split master weight for xpu only support sgd\n",
      "2025-02-24 03:46:16,176 - _logger.py - IPEX - INFO - Linear BatchNorm folding failed during the optimize process.\n",
      "Checkpoint destination directory unrahul/gemma-2b-dolly-qa/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "ERROR: ld.so: object '/lib/libtcmalloc.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./unrahul/gemma-2b-dolly-qa/checkpoint-500)... Done. 0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  1048.22\n",
      "Samples/second:  8.55\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▄▂▁▁</td></tr><tr><td>eval/runtime</td><td>█▁▁▁▂</td></tr><tr><td>eval/samples_per_second</td><td>▁███▇</td></tr><tr><td>eval/steps_per_second</td><td>▁███▇</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▄▄▆▆▇▇█</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▄▄▆▆▇▇█</td></tr><tr><td>train/grad_norm</td><td>█▇▁▃▇</td></tr><tr><td>train/learning_rate</td><td>█▆▅▃▁</td></tr><tr><td>train/loss</td><td>█▃▂▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>2.85106</td></tr><tr><td>eval/runtime</td><td>7.9849</td></tr><tr><td>eval/samples_per_second</td><td>25.924</td></tr><tr><td>eval/steps_per_second</td><td>3.256</td></tr><tr><td>train/epoch</td><td>11.03</td></tr><tr><td>train/global_step</td><td>560</td></tr><tr><td>train/grad_norm</td><td>3.21875</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>2.8897</td></tr><tr><td>train/total_flos</td><td>5.556293503392154e+16</td></tr><tr><td>train/train_loss</td><td>3.07188</td></tr><tr><td>train/train_runtime</td><td>1048.2241</td></tr><tr><td>train/train_samples_per_second</td><td>8.548</td></tr><tr><td>train/train_steps_per_second</td><td>0.534</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">wobbly-oath-12</strong> at: <a href='https://wandb.ai/steven_tran1-umass-lowell/gemma_dolly-qa/runs/pplxuci7' target=\"_blank\">https://wandb.ai/steven_tran1-umass-lowell/gemma_dolly-qa/runs/pplxuci7</a><br> View project at: <a href='https://wandb.ai/steven_tran1-umass-lowell/gemma_dolly-qa' target=\"_blank\">https://wandb.ai/steven_tran1-umass-lowell/gemma_dolly-qa</a><br>Synced 5 W&B file(s), 0 media file(s), 20 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250224_033045-pplxuci7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import transformers\n",
    "import wandb\n",
    "\n",
    "from trl import SFTTrainer\n",
    "\n",
    "os.environ[\"WANDB_PROJECT\"] = \"gemma_dolly-qa\"  \n",
    "os.environ[\"WANDB_LOG_MODEL\"] = \"checkpoint\"\n",
    "os.environ[\"IPEX_TILE_AS_DEVICE\"] = \"1\"\n",
    "\n",
    "finetuned_model_id = \"unrahul/gemma-2b-dolly-qa\"\n",
    "PUSH_TO_HUB = True\n",
    "USE_WANDB = True\n",
    "\n",
    "# Calculate max_steps based on the subset size\n",
    "num_train_samples = len(train_dataset)\n",
    "batch_size = 2\n",
    "gradient_accumulation_steps = 8\n",
    "steps_per_epoch = num_train_samples // (batch_size * gradient_accumulation_steps)\n",
    "num_epochs = 5\n",
    "max_steps = steps_per_epoch * num_epochs\n",
    "print(f\"Finetuning for max number of steps: {max_steps}\")\n",
    "\n",
    "def print_training_summary(results):\n",
    "    print(f\"Time: {results.metrics['train_runtime']: .2f}\")\n",
    "    print(f\"Samples/second: {results.metrics['train_samples_per_second']: .2f}\")\n",
    "    get_memory_usage()\n",
    "\n",
    "training_args = transformers.TrainingArguments(\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "        warmup_ratio=0.05,\n",
    "        max_steps=max_steps,\n",
    "        learning_rate=1e-5,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        save_steps=500,\n",
    "        bf16=True,\n",
    "        logging_steps=100,\n",
    "        output_dir=finetuned_model_id,\n",
    "        hub_model_id=finetuned_model_id if PUSH_TO_HUB else None,\n",
    "        use_ipex=True,\n",
    "        report_to=\"wandb\" if USE_WANDB else None,\n",
    "        #push_to_hub=PUSH_TO_HUB,\n",
    "        max_grad_norm=0.6,\n",
    "        weight_decay=0.01,\n",
    "        group_by_length=True\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validation_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    peft_config=lora_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=512,\n",
    "    packing=True\n",
    ")\n",
    "\n",
    "if device != \"cpu\":\n",
    "    print_memory_usage()\n",
    "    torch.xpu.empty_cache()\n",
    "results = trainer.train()\n",
    "print_training_summary(results)\n",
    "wandb.finish()\n",
    "\n",
    "# save lora model\n",
    "tuned_lora_model = \"gemma-2b-dolly-qa-lora\"\n",
    "trainer.model.save_pretrained(tuned_lora_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d17f19cf-291a-46b4-abb8-3b0933c30fca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88f3b2ab22b947ebadf554c157ddd803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "tuned_model = \"gemma-2b-dolly-qa\"\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    low_cpu_mem_usage=True,\n",
    "    return_dict=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "model = PeftModel.from_pretrained(base_model, tuned_lora_model)\n",
    "model = model.merge_and_unload()\n",
    "# save final tuned model\n",
    "model.save_pretrained(tuned_model)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "#model2 = ipex.optimize_transformers(model)  # optimize the model using `ipex`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ae174f3-50a4-49a5-a625-0468f46b35a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the main differences between a vegetarian and a vegan diet?\n",
      "\n",
      "A 100-W lightbulb is plugged into a standard $120-\\mathrm{V}$ (rms) outlet. Find $(a) I_{\\text {mas }}$ and $(b) I_{\\max }$ if a \"slow-motion\" camera were able to show the amplitude of the current more than once in $1.00 \\mathrm{~ms}$.\n",
      "\n",
      "A 100-turn coil has a radius of 4.50 cm and a resistance of 0.600 $\\Omega$. The coil is in a uniform magnetic field that is perpendicular to the plane of the coil. Find the time required for the magnetic field to change from 1.50 T to 0 T if the average induced current in the coil is 75.0 $\\mu A$.\n",
      "\n",
      "A 100-W lightbulb is plugged into a standard 120-V outlet. (a) How much does it cost per \n",
      "What are some effective strategies for managing stress and anxiety?\n",
      "\n",
      "Answer:\n",
      "\n",
      "Step 1/10\n",
      "1. Exercise: Regular exercise can help reduce stress and anxiety by releasing endorphins, which are natural mood-boosting chemicals in the brain.\n",
      "\n",
      "Step 2/10\n",
      "2. Meditation: Practicing meditation can help you focus on your breath and clear your mind, which can help reduce stress and anxiety.\n",
      "\n",
      "Step 3/10\n",
      "3. Journaling: Writing down your thoughts and feelings can help you process and understand them, which can reduce stress and anxiety.\n",
      "\n",
      "Step 4/10\n",
      "4. Deep breathing: Taking deep breaths can help you relax and reduce stress and anxiety.\n",
      "\n",
      "Step 5/10\n",
      "5. Relaxation techniques: There are many relaxation techniques, such as progressive muscle relaxation, deep breathing, and visualization, that can help you relax and reduce stress and anxiety.\n",
      "\n",
      "Step 6/10\n",
      "6. Healthy eating: Eating a balanced diet can help reduce stress and anxiety\n",
      "Can you explain the concept of blockchain technology in simple terms?\n",
      "\n",
      "Answer:\n",
      "\n",
      "Blockchain technology is a distributed ledger that records transactions between parties in a secure and transparent manner. It is a decentralized system that allows for the creation of a shared record of transactions that cannot be altered or tampered with.\n",
      "Blockchain technology is used in a variety of industries, including finance, healthcare, and supply chain management. It is also being used to create decentralized applications (dApps) that allow users to interact with each other and with the blockchain network.\n",
      "What are the key factors that influence the price of crude oil in global markets?\n",
      "\n",
      "Answer:\n",
      "\n",
      "Step 1/5\n",
      "1. Supply and demand: The most significant factor that influences the price of crude oil is the supply and demand of crude oil in the global market. When there is a surplus of crude oil, the price will decrease, and when there is a shortage, the price will increase.\n",
      "\n",
      "Step 2/5\n",
      "2. Geopolitical factors: Political instability, war, and sanctions can significantly impact the supply of crude oil. For example, the conflict between Russia and Ukraine has led to a decrease in the supply of crude oil, which has increased the price.\n",
      "\n",
      "Step 3/5\n",
      "3. Economic factors: The economic situation of the world also plays a significant role in the price of crude oil. When the global economy is booming, the demand for crude oil increases, and the price increases. On the other hand, when the economy is slowing down, the demand for crude oil decreases, and the price decreases.\n",
      "\n",
      "Step 4/\n",
      "When did Virgin Australia start operating?\n",
      "\n",
      "Virgin Australia started operating in 2000.\n",
      "\n",
      "What is Virgin Australia’s head office?\n",
      "\n",
      "Virgin Australia’s head office is located in Melbourne, Australia.\n",
      "\n",
      "What is Virgin Australia’s IATA code?\n",
      "\n",
      "Virgin Australia’s IATA code is VA.\n",
      "\n",
      "What is Virgin Australia’s call sign?\n",
      "\n",
      "Virgin Australia’s call sign is VA.\n",
      "\n",
      "What is Virgin Australia’s website?\n",
      "\n",
      "Virgin Australia’s website is www.virginaustralia.com.\n",
      "\n",
      "What is Virgin Australia’s Facebook page?\n",
      "\n",
      "Virgin Australia’s Facebook page is www.facebook.com/virginaustralia.\n",
      "\n",
      "What is Virgin Australia’s Twitter page?\n",
      "\n",
      "Virgin Australia’s Twitter page is www.twitter.com/virginaustralia.\n",
      "\n",
      "What is Virgin Australia’s Instagram page?\n",
      "\n",
      "Virgin Australia’s Instagram page is www.instagram.com/virginaustralia.\n",
      "\n",
      "What is Virgin Australia’s YouTube\n"
     ]
    }
   ],
   "source": [
    "test_inputs = [\n",
    "    \"What are the main differences between a vegetarian and a vegan diet?\",\n",
    "    \"What are some effective strategies for managing stress and anxiety?\",\n",
    "    \"Can you explain the concept of blockchain technology in simple terms?\",\n",
    "    \"What are the key factors that influence the price of crude oil in global markets?\",\n",
    "    \"When did Virgin Australia start operating?\"\n",
    "]\n",
    "device = \"xpu:0\"\n",
    "\n",
    "model = model.to(device)\n",
    "for text in test_inputs:\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(**inputs, max_new_tokens=200, \n",
    "                             do_sample=False, top_k=100,temperature=0.1, \n",
    "                             eos_token_id=tokenizer.eos_token_id)\n",
    "    print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3565ce-bfda-4cb7-8504-7f5004c78d48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.6",
   "language": "python",
   "name": "pytorch-2.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
