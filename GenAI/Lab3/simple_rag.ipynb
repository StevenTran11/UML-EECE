{
 "cells": [
  {
   "cell_type": "raw",
   "id": "0",
   "metadata": {},
   "source": [
    "SPDX-License-Identifier: Apache-2.0\n",
    "Copyright (c) 2025, Rahul Unnikrishnan Nair <rahul.unnikrishnan.nair@intel.com>\n",
    "Copyright (c) 2023, Eduardo Alvarez <eduardo.a.alvarez@intel.com>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Retrieval Augmented Generation (RAG) with Hugging Face Transformers on Intel® Data Center GPU\n",
    "\n",
    "#### 1. Retrieval Augmented Generation (RAG):\n",
    "Retrieval Augmented Generation (RAG) is a novel approach that combines the strengths of large-scale retrieval systems with the generative capabilities of transformer models like Falcon. In our RAG-based system, implemented on Intel® Data Center GPU Max Series 1100, when a question is posed, relevant documents or passages are retrieved from a corpus, and then fed alongside the query to the language model. This two-step process enables the model to leverage both external knowledge from the corpus and its internal knowledge to produce more informed and contextually accurate responses.\n",
    "\n",
    "#### 2. In-context Learning:\n",
    "Traditional machine learning models learn from extensive labeled datasets. In contrast, in-context learning pertains to models, especially language models, leveraging a few examples or context provided at inference time to tailor their outputs. Our implementation with Falcon3-1B-Instruct demonstrates this capability through efficient context processing using the Transformers pipeline.\n",
    "\n",
    "#### 3. LLM Chains/Pipelines:\n",
    "LLM chains or pipelines involve stringing together multiple stages or components of a system to achieve a complex task. In our RAG system, the pipeline includes a vector database for efficient retrieval, followed by the Hugging Face Transformers pipeline for response generation. This modular approach allows for easy optimization and updates to individual components.\n",
    "\n",
    "#### 4. RAG for On-Premise LLM Applications:\n",
    "With the growing need for data privacy and proprietary data handling, many enterprises seek solutions to harness the power of LLMs in-house. Our implementation, leveraging Intel's GPU infrastructure, demonstrates how RAG can be deployed effectively on-premise. By integrating RAG with local data repositories and utilizing hardware acceleration, enterprises can build powerful LLM applications tailored to their specific needs while ensuring data confidentiality.\n",
    "\n",
    "#### 5. RAG vs Fine-Tuning:\n",
    "While RAG is a powerful approach on its own, it can also be combined with different model architectures to enhance LLM capabilities. Our implementation focuses on using RAG with the Falcon3-1B-Instruct model, demonstrating how external knowledge retrieval can complement the model's built-in capabilities. This approach allows for dynamic knowledge integration without the need for continuous model retraining."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Getting Started\n",
    "1. Run the installation cell (first time only)\n",
    "2. Execute all cells in order\n",
    "3. The interactive interface will appear in the final cell\n",
    "4. Select your preferences and start chatting!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Install dependencies. Only run the first time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langchain in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (0.3.23)\n",
      "Requirement already satisfied: accelerate in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (1.6.0)\n",
      "Requirement already satisfied: transformers in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (4.51.1)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.51.2-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: datasets in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (3.5.0)\n",
      "Requirement already satisfied: tiktoken in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (0.9.0)\n",
      "Requirement already satisfied: chromadb in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (1.0.3)\n",
      "Collecting chromadb\n",
      "  Downloading chromadb-1.0.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: sentence_transformers in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (4.0.2)\n",
      "Requirement already satisfied: langchain-community in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (0.3.21)\n",
      "Requirement already satisfied: ipywidgets in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (8.1.5)\n",
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.6-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from langchain) (0.3.51)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from langchain) (0.3.27)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from langchain) (2.11.3)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from langchain) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from accelerate) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from accelerate) (24.2)\n",
      "Requirement already satisfied: psutil in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from accelerate) (6.1.1)\n",
      "Requirement already satisfied: torch>=2.0.0 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from accelerate) (2.6.0+xpu)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from accelerate) (0.30.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from datasets) (3.11.14)\n",
      "Requirement already satisfied: build>=1.0.3 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from chromadb) (1.2.2.post1)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from chromadb) (0.7.6)\n",
      "Requirement already satisfied: fastapi==0.115.9 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from chromadb) (0.115.9)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from chromadb) (3.23.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from chromadb) (4.12.2)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from chromadb) (1.21.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from chromadb) (1.31.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from chromadb) (1.31.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from chromadb) (0.52b1)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from chromadb) (1.31.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from chromadb) (1.71.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from chromadb) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from chromadb) (0.15.2)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from chromadb) (32.0.1)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from chromadb) (9.1.2)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from chromadb) (5.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from chromadb) (3.10.16)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from chromadb) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from chromadb) (13.9.4)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from chromadb) (4.23.0)\n",
      "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from fastapi==0.115.9->chromadb) (0.45.3)\n",
      "Requirement already satisfied: scikit-learn in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from sentence_transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from sentence_transformers) (1.15.1)\n",
      "Requirement already satisfied: Pillow in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from sentence_transformers) (11.0.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from langchain-community) (2.8.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from ipywidgets) (8.31.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from ipywidgets) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.14 (from ipywidgets)\n",
      "  Downloading widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab_widgets~=3.0.14 (from ipywidgets)\n",
      "  Downloading jupyterlab_widgets-3.0.14-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from aiohttp->datasets) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from aiohttp->datasets) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: pyproject_hooks in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from build>=1.0.3->chromadb) (2.2.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: anyio in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb) (4.9.0)\n",
      "Requirement already satisfied: certifi in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
      "Requirement already satisfied: idna in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: decorator in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: exceptiongroup in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (1.2.2)\n",
      "Requirement already satisfied: jedi>=0.16 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from jsonschema>=4.19.0->chromadb) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from jsonschema>=4.19.0->chromadb) (0.24.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (1.33)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: coloredlogs in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
      "Requirement already satisfied: protobuf in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (5.29.4)\n",
      "Requirement already satisfied: sympy in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
      "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.69.2)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.31.1 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.31.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.31.1 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.31.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.52b1 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.52b1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.52b1 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.52b1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.52b1 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.52b1)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.52b1 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.52b1)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.52b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
      "Requirement already satisfied: asgiref~=3.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from opentelemetry-instrumentation-asgi==0.52b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: greenlet>=1 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: networkx in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt==2025.0.2 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (2025.0.2)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2025.0.2 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (2025.0.2)\n",
      "Requirement already satisfied: intel-cmplr-lic-rt==2025.0.2 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (2025.0.2)\n",
      "Requirement already satisfied: intel-sycl-rt==2025.0.2 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (2025.0.2)\n",
      "Requirement already satisfied: tcmlib==1.2.0 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.2.0)\n",
      "Requirement already satisfied: umf==0.9.1 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (0.9.1)\n",
      "Requirement already satisfied: intel-pti==0.10.0 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (0.10.0)\n",
      "Requirement already satisfied: pytorch-triton-xpu==3.2.0 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.5)\n",
      "Requirement already satisfied: websockets>=10.4 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.6.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: zipp>=3.20 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: executing>=1.2.0 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Downloading transformers-4.51.2-py3-none-any.whl (10.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading chromadb-1.0.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ipywidgets-8.1.6-py3-none-any.whl (139 kB)\n",
      "Downloading jupyterlab_widgets-3.0.14-py3-none-any.whl (213 kB)\n",
      "Downloading widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: widgetsnbextension, jupyterlab_widgets, ipywidgets, transformers, chromadb\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.51.1\n",
      "    Uninstalling transformers-4.51.1:\n",
      "      Successfully uninstalled transformers-4.51.1\n",
      "  Attempting uninstall: chromadb\n",
      "    Found existing installation: chromadb 1.0.3\n",
      "    Uninstalling chromadb-1.0.3:\n",
      "      Successfully uninstalled chromadb-1.0.3\n",
      "Successfully installed chromadb-1.0.4 ipywidgets-8.1.6 jupyterlab_widgets-3.0.14 transformers-4.51.2 widgetsnbextension-4.0.14\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "%pip install --upgrade langchain accelerate transformers datasets tiktoken chromadb sentence_transformers langchain-community ipywidgets --no-warn-script-location\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "The code below builds RAGBot. RAGBot class is a streamlined implementation of a Retrieval-Augmented Generation (RAG) chatbot, designed to integrate large language models for generating contextually relevant responses. At its core, it manages the downloading and initialization of HuggingFace Transformer models, such as the \"Falcon3-1B-Instruct\" model, with support for handling large model files. Running on Intel® Data Center GPU Max Series 1100, the system leverages hardware acceleration for efficient model inference. It automates the process of fetching and structuring dialogue datasets from predefined sources. The chatbot utilizes the HuggingFace Transformers library, allowing for efficient model inference with adjustable parameters like the number of threads and maximum tokens. A key feature of RAGBot is its ability to build a vector database for text retrieval, significantly bolstering its ability to pull relevant document snippets based on user queries. This functionality, combined with a retrieval mechanism and an inference method using the Transformers pipeline, makes RAGBot a simple tool for developers aiming to learn about RAG and leverage this implementation as a basis for their implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Package Imports\n",
    "\n",
    "Core libraries for RAG implementation including Hugging FaceTransformers, LangChain components, and utilities for UI and data handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import requests\n",
    "import contextlib\n",
    "import pandas as pd\n",
    "import time\n",
    "import io\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb19dd0-2659-4595-8cb0-0e65035b574c",
   "metadata": {},
   "source": [
    "### RAGBot Class Implementation\n",
    "\n",
    "The RAGBot class implements a Retrieval-Augmented Generation system optimized for Intel® Data Center GPU Max Series 1100. Key components include:\n",
    "\n",
    "#### Core Features\n",
    "- Model Management: Handles initialization of Hugging Face Transformer models (currently supporting Falcon3-1B-Instruct)\n",
    "- Dataset Handling: Manages dialogue datasets from various domains (robot maintenance, sports coaching, academia, retail)\n",
    "- Vector Database: Creates and manages embeddings for efficient text retrieval\n",
    "- RAG Pipeline: Combines context retrieval with language model inference\n",
    "\n",
    "#### Key Methods\n",
    "- `get_model()`: Initializes the specified language model\n",
    "- `download_dataset()`: Fetches and processes dialogue datasets\n",
    "- `load_model()`: Configures the transformer model with specified parameters\n",
    "- `build_vectordb()`: Creates a searchable vector database from text data\n",
    "- `retrieval_mechanism()`: Implements context retrieval based on user queries\n",
    "- `inference()`: Generates responses using the loaded model and retrieved context\n",
    "\n",
    "The implementation leverages Hugging Face Transformers for model operations and LangChain for RAG functionality, providing a streamlined approach to context-aware response generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGBot:\n",
    "    \"\"\"\n",
    "    A class to handle model downloading, dataset management, model loading, vector database\n",
    "    creation, retrieval mechanisms, and inference for a response generation bot.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.model_name = \"\"\n",
    "        self.data_path = \"\"\n",
    "        self.user_input = \"\"\n",
    "        self.model = \"\"\n",
    "        self.max_tokens = 50\n",
    "        self.top_k = 50\n",
    "\n",
    "    def get_model(self, model, chunk_size: int = 10000):\n",
    "        self.model = model\n",
    "        if self.model == \"Falcon\":\n",
    "            self.model_name = \"tiiuae/Falcon3-1B-Instruct\"\n",
    "        elif model == \"Falcon2\":\n",
    "            self.model_name = \"tiiuae/Falcon3-7B-Base\"\n",
    "        elif model == \"More Models Coming Soon!\":\n",
    "            print(\"More models coming soon, defaulting to Falcon for now!\")\n",
    "            self.model_name = \"tiiuae/Falcon3-1B-Instruct\"\n",
    "\n",
    "    def download_dataset(self, dataset):\n",
    "        self.data_path = dataset + '_dialogues.txt'\n",
    "        if not os.path.isfile(self.data_path):\n",
    "            datasets = {\n",
    "                \"robot maintenance\": \"FunDialogues/customer-service-robot-support\", \n",
    "                \"basketball coach\": \"FunDialogues/sports-basketball-coach\", \n",
    "                \"physics professor\": \"FunDialogues/academia-physics-office-hours\",\n",
    "                \"grocery cashier\" : \"FunDialogues/customer-service-grocery-cashier\"\n",
    "            }\n",
    "            dataset = load_dataset(f\"{datasets[dataset]}\")\n",
    "            dialogues = dataset['train']\n",
    "            df = pd.DataFrame(dialogues, columns=['id', 'description', 'dialogue'])\n",
    "            dialog_df = df['dialogue']\n",
    "            dialog_df.to_csv(self.data_path, sep=' ', index=False)\n",
    "        else:\n",
    "            print('data already exists in path.')        \n",
    "\n",
    "    def load_model(self, n_threads, max_tokens, repeat_penalty, n_batch, top_k):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        self.llm = AutoModelForCausalLM.from_pretrained(\n",
    "            self.model_name,\n",
    "            torch_dtype=\"auto\",\n",
    "            device_map=\"auto\"\n",
    "        )\n",
    "        self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        self.llm.config.pad_token_id = self.llm.config.eos_token_id\n",
    "        self.max_tokens = max_tokens\n",
    "        self.top_k = top_k\n",
    "\n",
    "    def build_vectordb(self, chunk_size, overlap):\n",
    "        loader = TextLoader(self.data_path)\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=overlap)\n",
    "        self.index = VectorstoreIndexCreator(\n",
    "            embedding=HuggingFaceEmbeddings(), \n",
    "            text_splitter=text_splitter\n",
    "        ).from_loaders([loader])\n",
    "\n",
    "    def retrieval_mechanism(self, user_input, top_k=1, context_verbosity=False, rag_off=False):\n",
    "        self.user_input = user_input\n",
    "        self.context_verbosity = context_verbosity   \n",
    "        results = self.index.vectorstore.similarity_search(self.user_input, k=top_k)\n",
    "        context = \"\\n\".join([document.page_content for document in results])\n",
    "        if self.context_verbosity:\n",
    "            print(f\"Retrieving information related to your question...\")\n",
    "            print(f\"Found this content which is most similar to your question: {context}\")\n",
    "        if rag_off:\n",
    "            self.full_prompt = f\"Question: {user_input}\\nAnswer:\"\n",
    "        else:     \n",
    "            self.full_prompt = f\"\"\"Context: {context}\\n\\nQuestion: {user_input}\\nAnswer:\"\"\"\n",
    "\n",
    "    def inference(self):\n",
    "        if self.context_verbosity:\n",
    "            print(f\"Your Query: {self.full_prompt}\")\n",
    "        \n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant. Use the provided context to answer questions accurately.\"},\n",
    "            {\"role\": \"user\", \"content\": self.full_prompt}\n",
    "        ]\n",
    "        text = self.tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "        model_inputs = self.tokenizer([text], return_tensors=\"pt\").to(self.llm.device)\n",
    "        generated_ids = self.llm.generate(\n",
    "            **model_inputs,\n",
    "            max_new_tokens=self.max_tokens,\n",
    "            top_k=self.top_k\n",
    "        )\n",
    "        generated_ids = [\n",
    "            output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "        ]\n",
    "        response = self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "        return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### Customizing Your RAG LLM Chatbot Experience\n",
    "\n",
    "Welcome to the RAG LLM Chatbot interface! This guide will help you understand how to use the various widgets to customize your chatbot experience.\n",
    "\n",
    "#### Interface Elements\n",
    "\n",
    "##### Model Selection\n",
    "- **Model Dropdown**: Choose the model for your chatbot.\n",
    "  - Currently using the Falcon3-1B-Instruct model from TII.\n",
    "  - More models will be added in future updates.\n",
    "\n",
    "##### Query Input\n",
    "- **Query Text Box**: Enter your query here.\n",
    "  - Type the question or statement you want the chatbot to respond to.\n",
    "  - The text area provides ample space for longer queries.\n",
    "\n",
    "##### Response Customization\n",
    "- **Top K Slider**: Adjust the number of top results to consider for generating responses.\n",
    "  - Slide to increase or decrease the value. The range is from 1 to 4.\n",
    "  - This adjusts how many similar context passages are retrieved for answering.\n",
    "\n",
    "- **RAG OFF Checkbox**: Toggle whether to use Retrieval-Augmented Generation (RAG) or not.\n",
    "  - Check this box if you want to turn off RAG and use only the base model for responses.\n",
    "  - Useful for comparing RAG-enhanced vs. basic model responses.\n",
    "\n",
    "##### Data Processing Settings\n",
    "- **Chunk Size Input**: Set the size of text chunks for processing.\n",
    "  - Enter a value to determine how large each text chunk should be (5-5000).\n",
    "  - This affects how the context documents are segmented for retrieval.\n",
    "\n",
    "- **Overlap Input**: Define the overlap size between chunks.\n",
    "  - Set a value for how much overlap there should be between text chunks (0-1000).\n",
    "  - Higher overlap can help maintain context continuity between chunks.\n",
    "\n",
    "##### Dataset and Performance\n",
    "- **Dataset Dropdown**: Choose the dataset for context retrieval.\n",
    "  - Options include: 'robot maintenance', 'basketball coach', 'physics professor', 'grocery cashier'.\n",
    "  - Each dataset provides different domain-specific knowledge.\n",
    "\n",
    "- **Threads Slider**: Select the number of threads for processing.\n",
    "  - Adjust the slider to set the number of threads (2-200).\n",
    "  - Higher values may improve performance on multi-core systems.\n",
    "\n",
    "- **Max Tokens Input**: Specify the maximum length of generated responses.\n",
    "  - Enter a value to set the token limit (5-500).\n",
    "  - Higher values allow for longer, more detailed responses.\n",
    "\n",
    "##### Submit Button\n",
    "- **Submit**: Click this button to process your query and generate a response.\n",
    "  - The response will appear in a styled blue box below the interface.\n",
    "\n",
    "### How to Use\n",
    "1. Select your desired model from the **Model Dropdown**.\n",
    "2. Type your query in the **Query Text Box**.\n",
    "3. Set the **Top K Slider** for context retrieval amount.\n",
    "4. Configure **Chunk Size** and **Overlap** for text processing.\n",
    "5. Choose a dataset from the **Dataset Dropdown**.\n",
    "6. Adjust performance parameters (**Threads**, **Max Tokens**).\n",
    "7. Toggle **RAG OFF** if you want to test the base model.\n",
    "8. Click **Submit** to generate the response.\n",
    "\n",
    "> Note: The first execution will load the model into memory and may take longer. Subsequent queries will be faster unless you change model-specific parameters like threads or max tokens.nse.\r\n",
    "\r\n",
    "Enjoy interacting with your custom RAG LLM Chatbot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_inputs(b):\n",
    "    \"\"\"\n",
    "    Process inputs from the interactive chat interface.\n",
    "    \"\"\"\n",
    "    global previous_threads, previous_max_tokens, previous_top_k, previous_dataset\n",
    "    global previous_chunk_size, previous_overlap\n",
    "\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        f = io.StringIO()\n",
    "        with contextlib.redirect_stdout(f), contextlib.redirect_stderr(f):\n",
    "            model = model_dropdown.value\n",
    "            query = query_text.value\n",
    "            top_k = top_k_slider.value\n",
    "            chunk_size = chunk_size_input.value\n",
    "            overlap = overlap_input.value\n",
    "            dataset = dataset_dropdown.value\n",
    "            threads = threads_slider.value\n",
    "            max_tokens = max_token_input.value\n",
    "            rag_off = rag_off_checkbox.value\n",
    "            \n",
    "            bot.get_model(model=model)\n",
    "            bot.download_dataset(dataset=dataset)\n",
    "            if (threads != previous_threads or max_tokens != previous_max_tokens or \n",
    "                top_k != previous_top_k):\n",
    "                print(\"Loading model with new parameters\")\n",
    "                bot.load_model(\n",
    "                    n_threads=threads,\n",
    "                    max_tokens=max_tokens,\n",
    "                    repeat_penalty=1.50,\n",
    "                    n_batch=threads,\n",
    "                    top_k=top_k\n",
    "                )\n",
    "                previous_threads = threads\n",
    "                previous_max_tokens = max_tokens\n",
    "                previous_top_k = top_k\n",
    "            \n",
    "            # Rebuild vector DB if needed\n",
    "            if (dataset != previous_dataset or chunk_size != previous_chunk_size or \n",
    "                overlap != previous_overlap):\n",
    "                print(\"Rebuilding vector DB\")\n",
    "                bot.build_vectordb(chunk_size=chunk_size, overlap=overlap)\n",
    "                previous_dataset = dataset\n",
    "                previous_chunk_size = chunk_size\n",
    "                previous_overlap = overlap\n",
    "            bot.retrieval_mechanism(\n",
    "                user_input=query, \n",
    "                top_k=2,\n",
    "                context_verbosity=True,\n",
    "                rag_off=rag_off\n",
    "            )\n",
    "            response = bot.inference()            \n",
    "            styled_response = f\"\"\"\n",
    "            <div style=\"\n",
    "                background-color: lightblue;\n",
    "                border-radius: 15px;\n",
    "                padding: 10px;\n",
    "                font-family: Arial, sans-serif;\n",
    "                color: black;\n",
    "                max-width: 600px;\n",
    "                word-wrap: break-word;\n",
    "                margin: 10px;\n",
    "                font-size: 14px;\">\n",
    "                {response}\n",
    "            </div>\n",
    "            \"\"\"\n",
    "            display(HTML(styled_response))\n",
    "\n",
    "def create_chat_interface():\n",
    "    \"\"\"\n",
    "    Create and display the interactive chat interface widgets.\n",
    "    \"\"\"\n",
    "    global model_dropdown, query_text, top_k_slider, rag_off_checkbox\n",
    "    global chunk_size_input, overlap_input, dataset_dropdown\n",
    "    global threads_slider, max_token_input, output\n",
    "    \n",
    "    model_dropdown = widgets.Dropdown(\n",
    "        options=['Falcon', 'Falcon2', 'More Models Coming Soon!'],\n",
    "        description='Model:',\n",
    "        disabled=False,\n",
    "    )\n",
    "    query_layout = widgets.Layout(width='400px', height='100px')\n",
    "    query_text = widgets.Textarea(\n",
    "        placeholder='Type your query here',\n",
    "        description='Query:',\n",
    "        disabled=False,\n",
    "        layout=query_layout\n",
    "    )\n",
    "    top_k_slider = widgets.IntSlider(\n",
    "        value=2,\n",
    "        min=1,\n",
    "        max=4,\n",
    "        step=1,\n",
    "        description='Top K:',\n",
    "        disabled=False,\n",
    "        continuous_update=False,\n",
    "        orientation='horizontal',\n",
    "        readout=True,\n",
    "        readout_format='d'\n",
    "    )\n",
    "    rag_off_checkbox = widgets.Checkbox(\n",
    "        value=False,\n",
    "        description='RAG OFF?',\n",
    "        disabled=False,\n",
    "        indent=False,\n",
    "        tooltip='Turn off RAG and use only the base model'\n",
    "    )\n",
    "    chunk_size_input = widgets.BoundedIntText(\n",
    "        value=500,\n",
    "        min=5,\n",
    "        max=5000,\n",
    "        step=1,\n",
    "        description='Chunk Size:',\n",
    "        disabled=False\n",
    "    )\n",
    "    overlap_input = widgets.BoundedIntText(\n",
    "        value=50,\n",
    "        min=0,\n",
    "        max=1000,\n",
    "        step=1,\n",
    "        description='Overlap:',\n",
    "        disabled=False\n",
    "    )\n",
    "    dataset_dropdown = widgets.Dropdown(\n",
    "        options=['robot maintenance',\n",
    "                 'basketball coach',\n",
    "                 'physics professor',\n",
    "                 'grocery cashier'],\n",
    "        description='Dataset:',\n",
    "        disabled=False,\n",
    "    )\n",
    "    threads_slider = widgets.IntSlider(\n",
    "        value=8,\n",
    "        min=2,\n",
    "        max=200,\n",
    "        step=1,\n",
    "        description='Threads:',\n",
    "        disabled=False,\n",
    "        continuous_update=False,\n",
    "        orientation='horizontal',\n",
    "        readout=True,\n",
    "        readout_format='d'\n",
    "    )\n",
    "    max_token_input = widgets.BoundedIntText(\n",
    "        value=50,\n",
    "        min=5,\n",
    "        max=500,\n",
    "        step=5,\n",
    "        description='Max Tokens:',\n",
    "        disabled=False\n",
    "    )\n",
    "\n",
    "    # Layout\n",
    "    left_column = widgets.VBox([\n",
    "        model_dropdown, \n",
    "        top_k_slider, \n",
    "        rag_off_checkbox,\n",
    "        chunk_size_input, \n",
    "        overlap_input, \n",
    "        dataset_dropdown, \n",
    "        threads_slider,\n",
    "        max_token_input\n",
    "    ])\n",
    "\n",
    "    submit_button = widgets.Button(description=\"Submit\")\n",
    "    submit_button.on_click(process_inputs)\n",
    "    right_column = widgets.VBox([query_text, submit_button])\n",
    "    interface_layout = widgets.HBox([left_column, right_column])\n",
    "    output = widgets.Output()\n",
    "    display(interface_layout, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09f732689ab5462b85f263a3e2cfcc80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(Dropdown(description='Model:', options=('Falcon', 'Falcon2', 'More Models Coming…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4a7cf75e17a4b96a5207a5e4f6cb12b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bot = RAGBot()\n",
    "previous_threads = None\n",
    "previous_max_tokens = None\n",
    "previous_top_k = None\n",
    "previous_dataset = None\n",
    "previous_chunk_size = None\n",
    "previous_overlap = None\n",
    "previous_temp = None\n",
    "\n",
    "# Create and display the interface\n",
    "create_chat_interface()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Disclaimer for Using Large Language Models\n",
    "\n",
    "Please be aware that while Large Language Models like Falcon are powerful tools for text generation, they may sometimes produce results that are unexpected, biased, or inconsistent with the given prompt. It's advisable to carefully review the generated text and consider the context and application in which you are using these models.\n",
    "\n",
    "Usage of these models must also adhere to the licensing agreements and be in accordance with ethical guidelines and best practices for AI. If you have any concerns or encounter issues with the models, please refer to the respective model cards and documentation provided in the links above.\n",
    "\n",
    "To the extent that any public or non-Intel datasets or models are referenced by or accessed using these materials those datasets or models are provided by the third party indicated as the content source. Intel does not create the content and does not warrant its accuracy or quality. By accessing the public content, or using materials trained on or with such content, you agree to the terms associated with that content and that your use complies with the applicable license.\n",
    "\n",
    " \n",
    "Intel expressly disclaims the accuracy, adequacy, or completeness of any such public content, and is not liable for any errors, omissions, or defects in the content, or for any reliance on the content. Intel is not liable for any liability or damages relating to your use of public content.\n",
    "\n",
    "Intel’s provision of these resources does not expand or otherwise alter Intel’s applicable published warranties or warranty disclaimers for Intel products or solutions, and no additional obligations, indemnifications, or liabilities arise from Intel providing such resources. Intel reserves the right, without notice, to make corrections, enhancements, improvements, and other changes to its materials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.6",
   "language": "python",
   "name": "pytorch-2.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
