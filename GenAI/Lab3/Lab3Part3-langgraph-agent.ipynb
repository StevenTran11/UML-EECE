{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## Lab 3 Part 3 - EECE.4860/5860 at UMass Lowell\n",
    "\n",
    "Complete the missing code to create a new tool, and execute a complex query that invokes the tools.\n",
    "\n",
    "This example uses LangGraph APIs.\n",
    "\n",
    "We will use ChatNVIDIA model because it supports local mode when working with LangGraph. You need to apply for a free API key via https://build.nvidia.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langchain in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (0.3.23)\n",
      "Collecting langgraph\n",
      "  Downloading langgraph-0.3.29-py3-none-any.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: langchain-community in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (0.3.21)\n",
      "Collecting langchain-huggingface\n",
      "  Downloading langchain_huggingface-0.1.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: langchain-nvidia-ai-endpoints in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (0.3.9)\n",
      "Requirement already satisfied: wikipedia in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (1.4.0)\n",
      "Requirement already satisfied: numexpr in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (2.10.2)\n",
      "Collecting pypdf\n",
      "  Downloading pypdf-5.4.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from langchain) (0.3.51)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from langchain) (0.3.27)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from langchain) (2.11.3)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from langchain) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph)\n",
      "  Downloading langgraph_checkpoint-2.0.24-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting langgraph-prebuilt<0.2,>=0.1.1 (from langgraph)\n",
      "  Downloading langgraph_prebuilt-0.1.8-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
      "  Downloading langgraph_sdk-0.1.61-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: xxhash<4.0.0,>=3.5.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from langgraph) (3.5.0)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from langchain-community) (3.11.14)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from langchain-community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from langchain-community) (2.8.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from langchain-community) (2.1.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from langchain-huggingface) (0.30.2)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from langchain-huggingface) (4.0.2)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from langchain-huggingface) (0.21.1)\n",
      "Requirement already satisfied: transformers>=4.39.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from langchain-huggingface) (4.51.2)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from wikipedia) (4.13.3)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from pypdf) (4.12.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: filelock in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2024.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (24.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.67.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (1.33)\n",
      "Collecting ormsgpack<2.0.0,>=1.8.0 (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph)\n",
      "  Downloading ormsgpack-1.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
      "Requirement already satisfied: httpx>=0.25.2 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
      "Requirement already satisfied: torch>=1.11.0 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.6.0+xpu)\n",
      "Requirement already satisfied: scikit-learn in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.6.1)\n",
      "Requirement already satisfied: scipy in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.15.1)\n",
      "Requirement already satisfied: Pillow in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (11.0.0)\n",
      "Requirement already satisfied: greenlet>=1 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from transformers>=4.39.0->langchain-huggingface) (2024.11.6)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from transformers>=4.39.0->langchain-huggingface) (0.5.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from beautifulsoup4->wikipedia) (2.6)\n",
      "Requirement already satisfied: anyio in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain) (3.0.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.13.1)\n",
      "Requirement already satisfied: networkx in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.4)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt==2025.0.2 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2025.0.2)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2025.0.2 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2025.0.2)\n",
      "Requirement already satisfied: intel-cmplr-lic-rt==2025.0.2 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2025.0.2)\n",
      "Requirement already satisfied: intel-sycl-rt==2025.0.2 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2025.0.2)\n",
      "Requirement already satisfied: tcmlib==1.2.0 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.2.0)\n",
      "Requirement already satisfied: umf==0.9.1 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (0.9.1)\n",
      "Requirement already satisfied: intel-pti==0.10.0 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (0.10.0)\n",
      "Requirement already satisfied: pytorch-triton-xpu==3.2.0 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.6.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /mount/opt/intel/miniforge3/envs/pytorch_2.6/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2.1.5)\n",
      "Downloading langgraph-0.3.29-py3-none-any.whl (144 kB)\n",
      "Downloading langchain_huggingface-0.1.2-py3-none-any.whl (21 kB)\n",
      "Downloading pypdf-5.4.0-py3-none-any.whl (302 kB)\n",
      "Downloading langgraph_checkpoint-2.0.24-py3-none-any.whl (42 kB)\n",
      "Downloading langgraph_prebuilt-0.1.8-py3-none-any.whl (25 kB)\n",
      "Downloading langgraph_sdk-0.1.61-py3-none-any.whl (47 kB)\n",
      "Downloading ormsgpack-1.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (223 kB)\n",
      "Installing collected packages: pypdf, ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langchain-huggingface, langgraph\n",
      "Successfully installed langchain-huggingface-0.1.2 langgraph-0.3.29 langgraph-checkpoint-2.0.24 langgraph-prebuilt-0.1.8 langgraph-sdk-0.1.61 ormsgpack-1.9.1 pypdf-5.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "%pip install --upgrade langchain langgraph langchain-community langchain-huggingface langchain-nvidia-ai-endpoints wikipedia numexpr pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def magic_function(input: int) -> int:\n",
    "    \"\"\"Applies a magic function to an input.\"\"\"\n",
    "    return input + 2\n",
    "\n",
    "tools = [magic_function]\n",
    "\n",
    "query = \"what is the value of magic_function(3)?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "309cf97ff3ce46edb3a20ac4aa3edb0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1283e2b451341bc8912dafa846c62df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/128 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9595c89198f4c289ce137dbf5773b96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/140k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "277722d8926e42aaa7c764c4d4391a9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_xlm-roberta_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de10278b290f492596f5c08e4a26a364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/690 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22209af2d093492fbd72327174d4c40f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "287d1edebf7142e2aaad4225c7a34d0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0e1220bb53347e5bfcd9fa18083fd83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c7b302d218547feb6ff5537f726877f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b59b07ebb3294114879c74a9f6008401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a883bc0091f4801883ff23ef8493447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/271 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u36e87926e39e265cdd3b4f969ee677d/.local/lib/python3.10/site-packages/langchain/indexes/vectorstore.py:171: UserWarning: Using InMemoryVectorStore as the default vectorstore.This memory store won't persist data. You should explicitlyspecify a vectorstore when using VectorstoreIndexCreator\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "from langchain_core.tools import tool\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "top_k = 1\n",
    "max_tokens = 512\n",
    "chunk_size=1000\n",
    "overlap=50\n",
    "\n",
    "# The new tool you need to create is a RAG tool that answer queries about DeepSeek-R1\n",
    "# The tool leverages a few APIs that you see in the simple_rag.ipynb example, including\n",
    "# RecursiveCharacterTextSplitter(), VectorstoreIndexCreator(), vectorstore.similarity_search()\n",
    "#\n",
    "loader = PyPDFLoader(\"https://arxiv.org/pdf/2501.12948.pdf\")\n",
    "docs = loader.load()\n",
    "# TODO: call  RecursiveCharacterTextSplitter() using chunk_size and overlap\n",
    "# text_splitter = ...\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=overlap)\n",
    "# TODO: split the docuement using text_splitter and docs\n",
    "# splits = ...\n",
    "splits = text_splitter.split_documents(docs)\n",
    "# TODO: create the vector database by calling VectorstoreIndexCreator()\n",
    "# TODO: using HuggingFaceEmbedding() and \"intfloat/multilingual-e5-large-instruct\" model\n",
    "#index = VectorstoreIndexCreator(\n",
    "#    embedding= ...,\n",
    "#    text_splitter=...\n",
    "#).from_loaders([loader])\n",
    "index = VectorstoreIndexCreator(\n",
    "    embedding=HuggingFaceEmbeddings(model_name=\"intfloat/multilingual-e5-large-instruct\"),\n",
    "    text_splitter=text_splitter\n",
    ").from_documents(splits)\n",
    "\n",
    "@tool\n",
    "def query_deepseek_r1_paper(input: Annotated[str, \"Query relating to DeepSeek-R1\"]) -> str:\n",
    "    \"\"\"Provides context that can be used to answer questions on DeepSeek-R1\"\"\"\n",
    "    \n",
    "    print(f\"Received input query: {input}\\n\")\n",
    "\n",
    "    # TODO: perform similarity search on the input and top_k\n",
    "    # results = ...\n",
    "    results = index.vectorstore.similarity_search(input, k=top_k)\n",
    "    if not results:\n",
    "        print(\"No results found for the query.\\n\\n\")\n",
    "        return \"no results\"\n",
    "    \n",
    "    # TODO: concatenate the results using \"\\n\" as a separator\n",
    "    # context = \n",
    "    context = \"\\n\".join([doc.page_content for doc in results])\n",
    "    if context:\n",
    "        print(f\"Context found:\\n{context}\\n\\n\")\n",
    "        \n",
    "    return context\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model(id='mistralai/mistral-large-2-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=None, supports_tools=True, supports_structured_output=True, base_model=None), Model(id='meta/llama-3.1-8b-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=None, supports_tools=True, supports_structured_output=True, base_model=None), Model(id='meta/llama-3.3-70b-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=None, supports_tools=True, supports_structured_output=True, base_model=None), Model(id='meta/llama-3.1-70b-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=None, supports_tools=True, supports_structured_output=True, base_model=None), Model(id='meta/llama-3.1-405b-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=None, supports_tools=True, supports_structured_output=True, base_model=None), Model(id='meta/llama-3.2-3b-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=None, supports_tools=True, supports_structured_output=True, base_model=None), Model(id='nv-mistralai/mistral-nemo-12b-instruct', model_type='chat', client='ChatNVIDIA', endpoint=None, aliases=None, supports_tools=True, supports_structured_output=True, base_model=None)]\n"
     ]
    }
   ],
   "source": [
    "#use ChatNVIDIA model because it supports local mode when working with LangGraph.\n",
    "#You need to apply for a free API key via https://build.nvidia.com\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "if not os.getenv(\"NVIDIA_API_KEY\"):\n",
    "    # Note: the API key should start with \"nvapi-\"\n",
    "    os.environ[\"NVIDIA_API_KEY\"] = getpass.getpass(\"Enter your NVIDIA API key: \")\n",
    "\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "\n",
    "#print(ChatNVIDIA.get_available_models())\n",
    "# not all the models in ChatNVIDIA supports tools.\n",
    "tool_models = [\n",
    "    model for model in ChatNVIDIA.get_available_models() if model.supports_tools\n",
    "]\n",
    "print(tool_models)\n",
    "\n",
    "llm_nvidia = ChatNVIDIA(model=\"meta/llama-3.1-70b-instruct\",\n",
    "                           temperature=0.1,\n",
    "                            max_tokens=512,\n",
    "                            top_p=1.0,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMMathChain, LLMChain\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain.agents import Tool, initialize_agent\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "wikipedia_wrapper = WikipediaAPIWrapper()\n",
    "wikipedia_tool = Tool(\n",
    "    name=\"Wikipedia\",\n",
    "    func=wikipedia_wrapper.run,\n",
    "    description=\"A tool for searching the Internet to find various information on the topics mentioned.\"\n",
    ")\n",
    "math_chain = LLMMathChain.from_llm(llm=llm_nvidia, verbose=True)\n",
    "calculator = Tool.from_function(\n",
    "    name=\"Calculator\",\n",
    "    func=math_chain.run,\n",
    "    description=\"A tool for solving mathematical problems. Provide only the mathematical expressions.\"\n",
    ")\n",
    "\n",
    "tools=[wikipedia_tool, calculator, magic_function, query_deepseek_r1_paper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMMathChain chain...\u001b[0m\n",
      "2006 ^ 0.43\u001b[32;1m\u001b[1;3m```text\n",
      "2006**0.43\n",
      "```\n",
      "...numexpr.evaluate(\"2006**0.43\")...\n",
      "\u001b[0m\n",
      "Answer: \u001b[33;1m\u001b[1;3m26.30281917656938\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Query 1: In what year was the film Departed with Leopnardo Dicaprio released? What is this year raised to the power of 0.43?\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Response 1: The film \"The Departed\" was released in 2006, and this year raised to the power of 0.43 is approximately 26.30281917656938.\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- \n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Query 2: Use the year the film Departed with Leopnardo Dicaprio was released to calculate the value of magic_function.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Response 2: The film \"The Departed\" was released in 2006. The value of magic_function for the input 2006 is 2008.\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- \n",
      "\n",
      "Received input query: DeepSeek-R1 limitations\n",
      "\n",
      "Context found:\n",
      "• General Capability:Currently, the capabilities of DeepSeek-R1 fall short of DeepSeek-V3\n",
      "in tasks such as function calling, multi-turn, complex role-playing, and JSON output.\n",
      "Moving forward, we plan to explore how long CoT can be leveraged to enhance tasks in\n",
      "these fields.\n",
      "• Language Mixing:DeepSeek-R1 is currently optimized for Chinese and English, which\n",
      "may result in language mixing issues when handling queries in other languages. For\n",
      "instance, DeepSeek-R1 might use English for reasoning and responses, even if the query is\n",
      "in a language other than English or Chinese. We aim to address this limitation in future\n",
      "updates.\n",
      "• Prompting Engineering:When evaluating DeepSeek-R1, we observe that it is sensitive\n",
      "to prompts. Few-shot prompting consistently degrades its performance. Therefore, we\n",
      "recommend users directly describe the problem and specify the output format using a\n",
      "zero-shot setting for optimal results.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Query 3: What are the main limitations of DeepSeek-R1?\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Response 3: The main limitations of DeepSeek-R1 are:\n",
      "\n",
      "1. General Capability: DeepSeek-R1's capabilities are currently not on par with DeepSeek-V3 in tasks such as function calling, multi-turn, complex role-playing, and JSON output.\n",
      "2. Language Mixing: DeepSeek-R1 is optimized for Chinese and English, which may result in language mixing issues when handling queries in other languages.\n",
      "3. Prompting Engineering: DeepSeek-R1 is sensitive to prompts, and few-shot prompting can degrade its performance. It is recommended to use a zero-shot setting for optimal results.\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "langgraph_agent_executor = create_react_agent(llm_nvidia, tools)\n",
    "\n",
    "# Increase the recursion limit in the configuration\n",
    "config = {\n",
    "   \"recursion_limit\": 20  # Increase the limit as needed\n",
    "}\n",
    "\n",
    "query1 = \"In what year was the film Departed with Leopnardo Dicaprio released? What is this year raised to the power of 0.43?\"\n",
    "\n",
    "query2 = \"Use the year the film Departed with Leopnardo Dicaprio was released to calculate the value of magic_function.\"\n",
    "\n",
    "query3 = \"What are the main limitations of DeepSeek-R1?\"\n",
    "\n",
    "messages1 = langgraph_agent_executor.invoke({\"messages\": [(\"human\", query1)]}, config=config)\n",
    "\n",
    "print('-'*200)\n",
    "print(\"Query 1:\", query1)\n",
    "print('-'*200)\n",
    "print(\"Response 1:\", messages1[\"messages\"][-1].content)\n",
    "print('-'*200, '\\n')\n",
    "\n",
    "messages2 = langgraph_agent_executor.invoke({\"messages\": [(\"human\", query2)]}, config=config)\n",
    "print('-'*200)\n",
    "print(\"Query 2:\", query2)\n",
    "print('-'*200)\n",
    "print(\"Response 2:\", messages2[\"messages\"][-1].content)\n",
    "print('-'*200, '\\n')\n",
    "\n",
    "\n",
    "messages3 = langgraph_agent_executor.invoke({\"messages\": [(\"human\", query3)]}, config=config)\n",
    "print('-'*200)\n",
    "print(\"Query 3:\", query3)\n",
    "print('-'*200)\n",
    "print(\"Response 3:\", messages3[\"messages\"][-1].content)\n",
    "print('-'*200, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.6",
   "language": "python",
   "name": "pytorch-2.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
